{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GPUS = 1\n",
    "BS_PER_GPU = 128\n",
    "\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "NUM_TRAIN_SAMPLES = 50000\n",
    "\n",
    "BASE_LEARNING_RATE = 0.1\n",
    "LR_SCHEDULE = [(0.1, 5), (0.01, 10)]\n",
    "\n",
    "NUM_EPOCHS_1 = 3\n",
    "NUM_EPOCHS_2 = 5\n",
    "INIT_EPOCH_2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, y):\n",
    "  x = tf.image.per_image_standardization(x)\n",
    "  return x, y\n",
    "\n",
    "\n",
    "def augmentation(x, y):\n",
    "    x = tf.image.resize_with_crop_or_pad(\n",
    "        x, HEIGHT + 8, WIDTH + 8)\n",
    "    x = tf.image.random_crop(x, [HEIGHT, WIDTH, NUM_CHANNELS])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x, y \n",
    "\n",
    "\n",
    "def schedule(epoch):\n",
    "  initial_learning_rate = BASE_LEARNING_RATE * BS_PER_GPU / 128\n",
    "  learning_rate = initial_learning_rate\n",
    "  for mult, start_epoch in LR_SCHEDULE:\n",
    "    if epoch >= start_epoch:\n",
    "      learning_rate = initial_learning_rate * mult\n",
    "    else:\n",
    "      break\n",
    "  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "  return learning_rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "tf.random.set_seed(22)\n",
    "train_dataset = train_dataset.shuffle(NUM_TRAIN_SAMPLES).map(augmentation).map(normalize).batch(BS_PER_GPU * NUM_GPUS, drop_remainder=True)\n",
    "test_dataset = test_dataset.map(normalize).batch(BS_PER_GPU * NUM_GPUS, drop_remainder=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (HEIGHT, WIDTH, NUM_CHANNELS)\n",
    "img_input = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "model = resnet.resnet56(img_input=img_input, classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.1)\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# checkpoint\n",
    "outputFolder = './output-cifar'\n",
    "if not os.path.exists(outputFolder):\n",
    "    os.makedirs(outputFolder)\n",
    "filepath=outputFolder+\"/model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint_callback = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \\\n",
    "                             save_best_only=False, save_weights_only=False, \\\n",
    "                             mode='auto', save_frequency=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 47/390 [==>...........................] - ETA: 19:10 - loss: 3.4356 - accuracy: 0.1715"
     ]
    }
   ],
   "source": [
    "# train the model for the first time\n",
    "model.fit(train_dataset,\n",
    "          epochs=NUM_EPOCHS_1, callbacks=[checkpoint_callback],\n",
    "          validation_data=test_dataset,\n",
    "          validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume training from the checkpoint\n",
    "model_info = model.fit(train_dataset,\n",
    "                       epochs=NUM_EPOCHS_2, callbacks=[checkpoint_callback],\n",
    "                       validation_data=test_dataset,\n",
    "                       validation_freq=1,\n",
    "                       initial_epoch = INIT_EPOCH_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)\n",
    "\n",
    "model.save('./output-cifar/model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
